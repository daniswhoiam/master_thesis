{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv\n",
    "import os\n",
    "dotenv.load_dotenv() # For OpenRouter API Key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUESTIONS_PATH = \"\" # Path to the MaScQA eval.json file\n",
    "MODEL_NAME = \"\"\n",
    "VECTOR_STORE_URL = \"\"\n",
    "EMBEDDING_MODEL = \"\"\n",
    "EMBEDDING_DIMENSIONS = 0\n",
    "COLLECTION_NAME = \"\"\n",
    "MAX_TOKENS = 1024\n",
    "TEMPERATURE = 0.0\n",
    "TOP_K = 60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.import_questions import import_questions\n",
    "questions = import_questions(QUESTIONS_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DocumentStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.dataclasses.document import Document\n",
    "from haystack_integrations.document_stores.qdrant import QdrantDocumentStore\n",
    "\n",
    "document_store = QdrantDocumentStore(\n",
    "\t\turl=VECTOR_STORE_URL,\n",
    "    index=COLLECTION_NAME,\n",
    "    embedding_dim=EMBEDDING_DIMENSIONS\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text-Embedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.components.embedders import SentenceTransformersTextEmbedder\n",
    "\n",
    "text_embedder = SentenceTransformersTextEmbedder(model=EMBEDDING_MODEL, progress_bar=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack_integrations.components.retrievers.qdrant import QdrantEmbeddingRetriever\n",
    "\n",
    "retriever = QdrantEmbeddingRetriever(document_store=document_store, top_k=TOP_K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.components.builders import PromptBuilder\n",
    "\n",
    "template = \"\"\"\n",
    "Solve the following question. Write the correct answer inside a list at the end. Use the given context to answer the question if it's helpful.\n",
    "\n",
    "Context:\n",
    "{% for document in documents %}\n",
    "    {{ document.content }}\n",
    "{% endfor %}\n",
    "\n",
    "Question: {{question}}\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "prompt_builder = PromptBuilder(template=template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.components.generators import OpenAIGenerator\n",
    "from haystack.utils import Secret\n",
    "\n",
    "generator = OpenAIGenerator(model=MODEL_NAME,\n",
    "                            api_key=Secret.from_env_var(\"OPENROUTER_API_KEY\"),\n",
    "                            api_base_url=\"https://openrouter.ai/api/v1\",\n",
    "                            generation_kwargs={\n",
    "                              \"max_tokens\": MAX_TOKENS,\n",
    "                              \"temperature\": TEMPERATURE,\n",
    "                            })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack import Pipeline\n",
    "\n",
    "basic_rag_pipeline = Pipeline()\n",
    "# Add components to your pipeline\n",
    "basic_rag_pipeline.add_component(\"text_embedder\", text_embedder)\n",
    "basic_rag_pipeline.add_component(\"retriever\", retriever)\n",
    "basic_rag_pipeline.add_component(\"prompt_builder\", prompt_builder)\n",
    "basic_rag_pipeline.add_component(\"llm\", generator)\n",
    "\n",
    "# Now, connect the components to each other\n",
    "basic_rag_pipeline.connect(\"text_embedder.embedding\", \"retriever.query_embedding\")\n",
    "basic_rag_pipeline.connect(\"retriever\", \"prompt_builder.documents\")\n",
    "basic_rag_pipeline.connect(\"prompt_builder\", \"llm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Take all dataframes in questions and concatenate them into one, using question keys as a new column topic\n",
    "df = pd.concat(questions.values(), keys=questions.keys(), names=[\"topic\"]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add columns for the results and analysis\n",
    "df[\"result\"] = \"\"\n",
    "df[\"filtered_result\"] = \"\"\n",
    "df[\"correct_result\"] = \"\"\n",
    "df[\"overlap\"] = 0\n",
    "df[\"error_type\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_rows = len(df[(df[\"result\"] == \"\") | (df[\"result\"] == \"ERROR\") | (df[\"result\"].str.contains(\"<!DOCTYPE html>\", na=False))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Get the total number of rows in the DataFrame for the progress bar\n",
    "total_rows = len(df[(df[\"result\"] == \"\") | (df[\"result\"] == \"ERROR\") | (df[\"result\"].str.contains(\"<!DOCTYPE html>\", na=False))])\n",
    "\n",
    "# Create a progress bar\n",
    "with tqdm(total=total_rows, desc=\"Processing rows\", dynamic_ncols=True) as pbar:\n",
    "    # Iterate over each row\n",
    "    for index, row in df.iterrows():\n",
    "        if row[\"result\"] != \"\" and row[\"result\"] != \"ERROR\" and not \"<!DOCTYPE html>\" in row[\"result\"]:\n",
    "            continue\n",
    "\n",
    "        # Get the question and the context\n",
    "        question = row[\"questions\"]\n",
    "        # Run the pipeline\n",
    "        try:\n",
    "            result = basic_rag_pipeline.run({\"text_embedder\": {\"text\": question}, \"prompt_builder\": {\"question\": question}})[\"llm\"][\"replies\"][0]\n",
    "        except Exception as e:\n",
    "            print(str(e))\n",
    "            result = \"ERROR\"\n",
    "        # Add to df\n",
    "        df.at[index, \"result\"] = result\n",
    "\n",
    "        # Update the progress bar\n",
    "        pbar.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "date = datetime.now().strftime(\"%Y%m%d%H%M\")\n",
    "FILE_EMBEDDING_NAME = EMBEDDING_MODEL.replace(\"/\", \"-\")\n",
    "MODEL_NAME_NO_SLASH = MODEL_NAME.replace(\"/\", \"-\")\n",
    "filename = f\"results_{MODEL_NAME_NO_SLASH}_{FILE_EMBEDDING_NAME}_{COLLECTION_NAME}_top{TOP_K}_{date}\"\n",
    "\n",
    "# Save the results to a new file\n",
    "df.to_csv(f\"./{filename}.csv\", index=False)\n",
    "\n",
    "# Save metadata\n",
    "metadata = {\n",
    "    \"model\": MODEL_NAME,\n",
    "    \"embedding\": EMBEDDING_MODEL,\n",
    "    \"collection\": COLLECTION_NAME,\n",
    "    \"date\": date,\n",
    "    \"num_rows\": len(df),\n",
    "    \"top_k\": TOP_K\n",
    "}\n",
    "\n",
    "with open(f'{filename}.json', 'w') as f:\n",
    "  json.dump(metadata, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "haystack",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
