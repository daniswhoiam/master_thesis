{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv\n",
    "import os\n",
    "dotenv.load_dotenv() # For OpenRouter API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUESTIONS_PATH = \"\" # Path of MaScQA eval.json file\n",
    "MODEL_NAME = \"\"\n",
    "MAX_TOKENS = 1024\n",
    "TEMPERATURE = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.import_questions import import_questions\n",
    "questions = import_questions(QUESTIONS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.components.builders import PromptBuilder\n",
    "\n",
    "template = \"\"\"\n",
    "Solve the following question. Write the correct answer inside a list at the end.\n",
    "Question: {{question}}\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "prompt_builder = PromptBuilder(template=template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.components.generators import OpenAIGenerator\n",
    "from haystack.utils import Secret\n",
    "\n",
    "generator = OpenAIGenerator(model=MODEL_NAME,\n",
    "                            api_key=Secret.from_env_var(\"OPENROUTER_API_KEY\"),\n",
    "                            api_base_url=\"https://openrouter.ai/api/v1\",\n",
    "                            generation_kwargs={\n",
    "                              \"max_tokens\": MAX_TOKENS,\n",
    "                              \"temperature\": TEMPERATURE,\n",
    "                            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack import Pipeline\n",
    "\n",
    "llm_pipeline = Pipeline()\n",
    "# Add components to your pipeline\n",
    "llm_pipeline.add_component(\"prompt_builder\", prompt_builder)\n",
    "llm_pipeline.add_component(\"llm\", generator)\n",
    "\n",
    "# Now, connect the components to each other\n",
    "llm_pipeline.connect(\"prompt_builder\", \"llm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Take all dataframes in questions and concatenate them into one, using question keys as a new column topic\n",
    "df = pd.concat(questions.values(), keys=questions.keys(), names=[\"topic\"]).reset_index()\n",
    "# Add columns for the results and analysis\n",
    "df[\"result\"] = \"\"\n",
    "df[\"filtered_result\"] = \"\"\n",
    "df[\"correct_result\"] = \"\"\n",
    "df[\"overlap\"] = 0\n",
    "df[\"error_type\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "# Get the total number of rows in the DataFrame for the progress bar\n",
    "total_rows = len(df[(df[\"result\"] == \"\") | (df[\"result\"] == \"ERROR\") | (df[\"result\"].str.contains(\"<!DOCTYPE html>\", na=False))])\n",
    "\n",
    "# Create a progress bar\n",
    "with tqdm(total=total_rows, desc=\"Processing rows\", dynamic_ncols=True) as pbar:\n",
    "    # Iterate over each row\n",
    "    for index, row in df.iterrows():\n",
    "        if row[\"result\"] != \"\" and row[\"result\"] != \"ERROR\" and not \"<!DOCTYPE html>\" in row[\"result\"]:\n",
    "            continue\n",
    "        \n",
    "        # Get the question and the context\n",
    "        question = row[\"questions\"]\n",
    "        # Run the pipeline\n",
    "        try:\n",
    "            result = llm_pipeline.run({\"prompt_builder\": {\"question\": question}})[\"llm\"][\"replies\"][0]\n",
    "        except Exception as e:\n",
    "            print(str(e))\n",
    "            result = \"ERROR\"\n",
    "        # Add to df\n",
    "        df.at[index, \"result\"] = result\n",
    "\n",
    "        # Update the progress bar\n",
    "        pbar.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "date = datetime.now().strftime(\"%Y%m%d%H%M\")\n",
    "MODEL_NAME_WITHOUT_SLASHES = MODEL_NAME.replace(\"/\", \"_\")\n",
    "filename = f\"results_{MODEL_NAME_WITHOUT_SLASHES}_{date}\"\n",
    "\n",
    "# Save the results to a new file\n",
    "df.to_csv(f\"{filename}.csv\", index=False)\n",
    "\n",
    "# Save metadata\n",
    "metadata = {\n",
    "    \"model\": MODEL_NAME,\n",
    "    \"date\": date,\n",
    "    \"num_rows\": len(df),\n",
    "}\n",
    "\n",
    "with open(f'{filename}.json', 'w') as f:\n",
    "  json.dump(metadata, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "haystack",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
